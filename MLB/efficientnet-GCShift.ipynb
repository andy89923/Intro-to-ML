{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ea186a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torchinfo import summary\n",
    "import torchsummary\n",
    "\n",
    "from torchvision import transforms\n",
    "from video_dataset import  VideoFrameDataset, ImglistToTensor\n",
    "from pytorchtools import EarlyStopping\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from thop import profile\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfa0a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "manualSeed = 996\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "#     torch.backends.cudnn.benchmark = True\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "torch.cuda.manual_seed(manualSeed)\n",
    "torch.cuda.manual_seed_all(manualSeed)\n",
    "np.random.seed(manualSeed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cc8420",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "num_segments = 8\n",
    "advprop = True\n",
    "image_size = 224 #b0\n",
    "# image_size = 299 #b3\n",
    "\n",
    "if advprop:  # for models using advprop pretrained weights\n",
    "    preprocess = transforms.Compose([\n",
    "            ImglistToTensor(),  # list of PIL images to (FRAMES x CHANNELS x HEIGHT x WIDTH) tensor\n",
    "            transforms.Resize(image_size),  # image batch, resize smaller edge to 299\n",
    "            transforms.CenterCrop(image_size),  # image batch, center crop to square 299x299\n",
    "            transforms.Lambda(lambda img: img * 2.0 - 1.0),\n",
    "    ])\n",
    "else:\n",
    "    preprocess = transforms.Compose([\n",
    "            ImglistToTensor(),  # list of PIL images to (FRAMES x CHANNELS x HEIGHT x WIDTH) tensor\n",
    "            transforms.Resize(image_size),  # image batch, resize smaller edge to 299\n",
    "            transforms.CenterCrop(image_size),  # image batch, center crop to square 299x299\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616ef496",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_root = \"../../UCF101_IMG/\"\n",
    "\n",
    "train1_dataset = VideoFrameDataset(\n",
    "    root_path=os.path.join(videos_root, \"train01\"),\n",
    "    annotationfile_path=os.path.join(videos_root, \"train01/annotations.txt\"),\n",
    "    num_segments=num_segments,\n",
    "    frames_per_segment=1,\n",
    "    imagefile_template='frame_{0:012d}.jpg',\n",
    "    transform=preprocess,\n",
    "    random_shift=True,\n",
    "    test_mode=False\n",
    ")\n",
    "train2_dataset = VideoFrameDataset(\n",
    "    root_path=os.path.join(videos_root, \"train02\"),\n",
    "    annotationfile_path=os.path.join(videos_root, \"train02/annotations.txt\"),\n",
    "    num_segments=num_segments,\n",
    "    frames_per_segment=1,\n",
    "    imagefile_template='frame_{0:012d}.jpg',\n",
    "    transform=preprocess,\n",
    "    random_shift=True,\n",
    "    test_mode=False\n",
    ")\n",
    "train3_dataset = VideoFrameDataset(\n",
    "    root_path=os.path.join(videos_root, \"train03\"),\n",
    "    annotationfile_path=os.path.join(videos_root, \"train03/annotations.txt\"),\n",
    "    num_segments=num_segments,\n",
    "    frames_per_segment=1,\n",
    "    imagefile_template='frame_{0:012d}.jpg',\n",
    "    transform=preprocess,\n",
    "    random_shift=True,\n",
    "    test_mode=False\n",
    ")\n",
    "\n",
    "test1_dataset = VideoFrameDataset(\n",
    "    root_path=os.path.join(videos_root, \"test01\"),\n",
    "    annotationfile_path=os.path.join(videos_root, \"test01/annotations.txt\"),\n",
    "    num_segments=num_segments,\n",
    "    frames_per_segment=1,\n",
    "    imagefile_template='frame_{0:012d}.jpg',\n",
    "    transform=preprocess,\n",
    "    random_shift=False,\n",
    "    test_mode=True\n",
    ")\n",
    "test2_dataset = VideoFrameDataset(\n",
    "    root_path=os.path.join(videos_root, \"test02\"),\n",
    "    annotationfile_path=os.path.join(videos_root, \"test02/annotations.txt\"),\n",
    "    num_segments=num_segments,\n",
    "    frames_per_segment=1,\n",
    "    imagefile_template='frame_{0:012d}.jpg',\n",
    "    transform=preprocess,\n",
    "    random_shift=False,\n",
    "    test_mode=True\n",
    ")\n",
    "test3_dataset = VideoFrameDataset(\n",
    "    root_path=os.path.join(videos_root, \"test03\"),\n",
    "    annotationfile_path=os.path.join(videos_root, \"test03/annotations.txt\"),\n",
    "    num_segments=num_segments,\n",
    "    frames_per_segment=1,\n",
    "    imagefile_template='frame_{0:012d}.jpg',\n",
    "    transform=preprocess,\n",
    "    random_shift=False,\n",
    "    test_mode=True\n",
    ")\n",
    "\n",
    "train1_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=train1_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=batch_size,\n",
    "    pin_memory=True\n",
    ")\n",
    "train2_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=train2_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=batch_size,\n",
    "    #pin_memory=True\n",
    ")\n",
    "train3_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=train3_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=batch_size,\n",
    "    #pin_memory=True\n",
    ")\n",
    "\n",
    "test1_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=test1_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=batch_size,\n",
    "    pin_memory=True\n",
    ")\n",
    "test2_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=test2_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=batch_size,\n",
    "    #pin_memory=True\n",
    ")\n",
    "test3_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=test3_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=batch_size,\n",
    "    #pin_memory=True\n",
    ")\n",
    "\n",
    "plot_test1_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=test1_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=1,\n",
    "#     pin_memory=True\n",
    ")\n",
    "plot_test2_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=test2_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=1,\n",
    "    #pin_memory=True\n",
    ")\n",
    "plot_test3_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=test3_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=1,\n",
    "    #pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42b799e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-3\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "milestones = [15,30,45]\n",
    "\n",
    "gamma = 0.3\n",
    "\n",
    "train1_size = len(train1_dataset)\n",
    "test1_size = len(test1_dataset)\n",
    "train2_size = len(train2_dataset)\n",
    "test2_size = len(test2_dataset)\n",
    "train3_size = len(train3_dataset)\n",
    "test3_size = len(test3_dataset)\n",
    "\n",
    "print(len(train1_dataset))\n",
    "print(len(test1_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b492ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs, criterion, train_loader, test_loader, opt, scheduler, train_size, test_size, device, model_name):\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    test_loss = []\n",
    "    test_acc = []\n",
    "    \n",
    "    batch_cnt = 0\n",
    "    \n",
    "    # initialize the early_stopping object\n",
    "    early_stopping = EarlyStopping(patience=15, verbose=True)\n",
    "#     early_stopping_cnt = 0\n",
    "    max_acc = 0\n",
    "#     model=nn.DataParallel(model,device_ids=[0, 1])\n",
    "    model.to(device)\n",
    "#     scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        correct = 0\n",
    "        temp = 0\n",
    "        acc = 0\n",
    "        model.train()\n",
    "        \n",
    "        for data, label in tqdm(train_loader):\n",
    "#             with torch.cuda.amp.autocast():\n",
    "\n",
    "                batch_cnt = batch_cnt + 1\n",
    "\n",
    "                x = data.to(device, dtype=torch.float)\n",
    "                y = label.to(device, dtype=torch.long)\n",
    "\n",
    "                pred = model(x)\n",
    "                loss = criterion(pred, y)\n",
    "                temp += loss.item()\n",
    "                correct += (torch.max(pred, 1)[1] == y).sum().item()\n",
    "\n",
    "                loss.backward()\n",
    "#                 scaler.scale(loss).backward()\n",
    "\n",
    "#                 if batch_cnt%2 == 0:\n",
    "#                     scaler.step(opt)\n",
    "#                     scaler.update()\n",
    "#                     opt.zero_grad()\n",
    "                opt.step()\n",
    "                opt.zero_grad()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        acc = correct / train_size\n",
    "        train_loss.append(temp/len(train_loader))\n",
    "        train_acc.append(acc)\n",
    "        \n",
    "        correct = 0\n",
    "        temp = 0\n",
    "        acc = 0\n",
    "    \n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, label in tqdm(test_loader):\n",
    "                \n",
    "                #x = data.to(device, dtype=torch.float)\n",
    "                x = data.cuda()\n",
    "                x = x.float()\n",
    "                y = label.to(device, dtype=torch.long)\n",
    "            \n",
    "                pred = model(x)\n",
    "                loss = criterion(pred, y)\n",
    "                temp += loss.item()\n",
    "                correct += (torch.max(pred, 1)[1] == y).sum().item()\n",
    "        \n",
    "        acc = correct / test_size\n",
    "        los = temp/len(test_loader)\n",
    "        \n",
    "        test_loss.append(los)\n",
    "        test_acc.append(acc)\n",
    "        \n",
    "        print(f'epoch:{epoch}/{epochs} ', end='')\n",
    "        if acc > max_acc:\n",
    "            max_acc = acc\n",
    "            torch.save(model, \"./saved_model/\"+model_name)\n",
    "            early_stopping.counter = 0\n",
    "            print(f\"Saving model with better accuracy: {acc:.2%}\", end='\\n')\n",
    "        else:\n",
    "            print(f\"Accuracy is not better than: {max_acc:.2%}\", end='\\n')\n",
    "        \n",
    "        early_stopping(test_loss[epoch-1], model)\n",
    "        \n",
    "        print(f\"{opt.param_groups[0]['lr']}\")\n",
    "        print(f\"train loss:{train_loss[epoch-1]:.2f}  train acc:{train_acc[epoch-1]:.2%}\", end ='\\n')\n",
    "        print(f\"test loss:{test_loss[epoch-1]:.2f}  test acc:{test_acc[epoch-1]:.2%}\")\n",
    "                \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "        \n",
    "    return train_acc, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facaa8ba",
   "metadata": {},
   "source": [
    "# Shift Conv & DCT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8e0865",
   "metadata": {},
   "source": [
    "## Split 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd36fdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = \"EFN_Cle112_allGC_Final_Shift\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6c9528",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from EfficientNet_GCShift import EfficientNet_GCShift\n",
    "\n",
    "EFN_model_1 = EfficientNet_GCShift(device, num_segments, batch_size).to(device)\n",
    "opt1 = optim.SGD(EFN_model_1.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "scheduler1 = optim.lr_scheduler.MultiStepLR(opt1, milestones=milestones,gamma=gamma)\n",
    "# scheduler1 = optim.lr_scheduler.ReduceLROnPlateau(opt1, mode='min', factor=0.3, patience=3)\n",
    "train1_acc = []\n",
    "test1_acc = []\n",
    "\n",
    "torchsummary.summary(EFN_model_1, (num_segments, 3, image_size, image_size))\n",
    "summary(EFN_model_1, input_size=(4, num_segments, 3, image_size, image_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3257f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train1_acc, test1_acc = train(EFN_model_1, epochs, criterion, train1_dataloader, test1_dataloader, opt1, scheduler1, train1_size, test1_size, device, modelName+\"_1.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e0ee01",
   "metadata": {},
   "source": [
    "## Split 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae21c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from EfficientNet_GCShift import EfficientNet_GCShift\n",
    "\n",
    "EFN_model_2 = EfficientNet_GCShift(device, num_segments, batch_size).to(device)\n",
    "opt2 = optim.SGD(EFN_model_2.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "scheduler2 = optim.lr_scheduler.MultiStepLR(opt2, milestones=milestones, gamma=gamma)\n",
    "# scheduler1 = optim.lr_scheduler.ReduceLROnPlateau(opt1, mode='min', factor=0.3, patience=3)\n",
    "train2_acc = []\n",
    "test2_acc = []\n",
    "\n",
    "torchsummary.summary(EFN_model_2, (num_segments, 3, image_size, image_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe86da4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train2_acc, test2_acc = train(EFN_model_2, epochs, criterion, train2_dataloader, test2_dataloader, opt2, scheduler2, train2_size, test2_size, device, modelName+\"_2.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eefcc06",
   "metadata": {},
   "source": [
    "## Split 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb2ed33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from EfficientNet_GCShift import EfficientNet_GCShift\n",
    "\n",
    "EFN_model_3 = EfficientNet_GCShift(device, num_segments, batch_size).to(device)\n",
    "opt3 = optim.SGD(EFN_model_3.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "scheduler3 = optim.lr_scheduler.MultiStepLR(opt3, milestones=milestones, gamma=gamma)\n",
    "# scheduler3 = optim.lr_scheduler.ReduceLROnPlateau(opt3, mode='min', factor=0.3, patience=3)\n",
    "train3_acc = []\n",
    "test3_acc = []\n",
    "\n",
    "torchsummary.summary(EFN_model_3, (num_segments, 3, image_size, image_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6465c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train3_acc, test3_acc = train(EFN_model_3, epochs, criterion, train3_dataloader, test3_dataloader, opt3, scheduler3, train3_size, test3_size, device, modelName+\"_3.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dustenv",
   "language": "python",
   "name": "dustenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
